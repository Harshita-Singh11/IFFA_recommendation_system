{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dcb14a-2bbb-4bc8-a808-9bbd974c0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8c8f8e0-799b-42f3-b7c2-feea6f6b7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IFFARecommendationSystem:\n",
    "    def __init__(self):\n",
    "        self.movies_df = None\n",
    "        self.ratings_df = None\n",
    "        self.users_df = None\n",
    "        self.content_matrix = None\n",
    "        self.user_item_matrix = None\n",
    "        self.svd_model = None\n",
    "    def load_data( self, movies_path, ratings_path = None, users_path = None):\n",
    "        '''\n",
    "        load movies, ratings and user data\n",
    "    \n",
    "        movies_path (str): Path to movies CSV file\n",
    "        ratings_path (str, optional): Path to ratings CSV file\n",
    "        users_path (str, optional): Path to users CSV file\n",
    "        '''\n",
    "        # Load movies data (required)\n",
    "        self.movies_df = pd.read_csv(movies_path)\n",
    "        print(f\"Loaded {len(self.movies_df)} movies\")\n",
    "        \n",
    "        # Load ratings data if provided\n",
    "        if ratings_path:\n",
    "            self.ratings_df = pd.read_csv(ratings_path)\n",
    "            print(f\"Loaded {len(self.ratings_df)} ratings\")\n",
    "        \n",
    "        # Load users data if provided\n",
    "        if users_path:\n",
    "            self.users_df = pd.read_csv(users_path)\n",
    "            print(f\"Loaded {len(self.users_df)} users\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7743524-2779-4713-8215-babaf09b659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(self):\n",
    "        \"\"\"Preprocess the data for recommendation algorithms\"\"\"\n",
    "        # Check if data is loaded\n",
    "        if self.movies_df is None:\n",
    "            raise ValueError(\"Data not loaded. Please call load_data first.\")\n",
    "        \n",
    "        # Create a combined features column for content-based filtering\n",
    "        # Assuming columns like 'genres', 'director', 'cast', 'keywords', etc.\n",
    "        # Adjust based on your actual dataset columns\n",
    "        features = []\n",
    "        \n",
    "        if 'genres' in self.movies_df.columns:\n",
    "            features.append('genres')\n",
    "        if 'director' in self.movies_df.columns:\n",
    "            features.append('director')\n",
    "        if 'cast' in self.movies_df.columns:\n",
    "            features.append('cast')\n",
    "        if 'keywords' in self.movies_df.columns:\n",
    "            features.append('keywords')\n",
    "        if 'tags' in self.movies_df.columns:\n",
    "            features.append('tags')\n",
    "        if 'description' in self.movies_df.columns:\n",
    "            features.append('description')\n",
    "            \n",
    "        # If no suitable columns found, use title as fallback\n",
    "        if not features and 'title' in self.movies_df.columns:\n",
    "            features.append('title')\n",
    "            \n",
    "        if not features:\n",
    "            raise ValueError(\"No suitable features found for content-based filtering\")\n",
    "            \n",
    "        # Create combined features\n",
    "        self.movies_df['combined_features'] = self.movies_df[features].apply(\n",
    "            lambda row: ' '.join(row.values.astype(str)), axis=1\n",
    "        )\n",
    "        \n",
    "        print(\"Data preprocessing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85caed04-38c2-420c-8662-6eeeffcd5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_content_based_model(self):\n",
    "        \"\"\"Build a content-based recommendation model using TF-IDF\"\"\"\n",
    "        if 'combined_features' not in self.movies_df.columns:\n",
    "            self.preprocess_data()\n",
    "            \n",
    "        # Create TF-IDF matrix\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        self.content_matrix = tfidf.fit_transform(self.movies_df['combined_features'])\n",
    "        \n",
    "        print(f\"Content-based model built with shape: {self.content_matrix.shape}\")\n",
    "        \n",
    "def get_content_based_recommendations(self, movie_id, n=10):\n",
    "    if self.content_matrix is None:\n",
    "        self.build_content_based_model()\n",
    "            \n",
    "        # Find the movie index\n",
    "    movie_idx = self.movies_df[self.movies_df['movie_id'] == movie_id].index\n",
    "    if len(movie_idx) == 0:\n",
    "        raise ValueError(f\"Movie ID {movie_id} not found\")\n",
    "    movie_idx = movie_idx[0]\n",
    "        \n",
    "    # Calculate similarity scores\n",
    "    similarity_scores = cosine_similarity(\n",
    "        self.content_matrix[movie_idx].reshape(1, -1), \n",
    "        self.content_matrix\n",
    "        ).flatten()\n",
    "        \n",
    "    # Get top n similar movies\n",
    "    similar_indices = similarity_scores.argsort()[::-1][1:n+1]  # Exclude the movie itself\n",
    "        \n",
    "    # Return recommended movies\n",
    "    recommendations = self.movies_df.iloc[similar_indices].copy()\n",
    "    recommendations['similarity_score'] = similarity_scores[similar_indices]\n",
    "        \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9fa2270-d1b7-407c-8545-7dc1917619a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_collaborative_filtering_model(self, n_components=50):\n",
    "    \"\"\"\n",
    "        Build a collaborative filtering model using SVD\"\"\"\n",
    "    if self.ratings_df is None:\n",
    "        raise ValueError(\"Ratings data not loaded. Cannot build collaborative filtering model.\")\n",
    "            \n",
    "        # Create user-item matrix\n",
    "    user_item_df = self.ratings_df.pivot(\n",
    "        index='user_id', \n",
    "        columns='movie_id', \n",
    "        values='rating'\n",
    "    ).fillna(0)\n",
    "    self.user_item_matrix = user_item_df.values\n",
    "    self.user_ids = user_item_df.index.tolist()\n",
    "    self.movie_ids_cf = user_item_df.columns.tolist()\n",
    "        \n",
    "        # Apply SVD\n",
    "    self.svd_model = TruncatedSVD(n_components=n_components)\n",
    "    self.user_features = self.svd_model.fit_transform(self.user_item_matrix)\n",
    "    self.movie_features = self.svd_model.components_.T\n",
    "        \n",
    "    print(f\"Collaborative filtering model built with {n_components} latent factors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eb0b524c-28ef-4a05-8d47-8886cd25b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collaborative_recommendations(self, user_id, n = 10):\n",
    "    \"\"\"get collaborative recommendation by filtering for a user\n",
    "    Parameters:\n",
    "        user_id: ID of the user to get recommendations for\n",
    "        n (int): Number of recommendations to return\n",
    "        \n",
    "        Returns:\n",
    "        DataFrame: Top n recommended movies for the user\n",
    "    \"\"\"\n",
    "    if self.svd_model is None:\n",
    "        raise ValueError(\"Collaborative filtering model not built\")\n",
    "\n",
    "    # Find user index\n",
    "    if user_id not in self.user_ids:\n",
    "        raise ValueError(f\"User ID {user_id} not found\")\n",
    "    user_idx = self.user_ids.index(user_id)\n",
    "        \n",
    "    # Get already rated movies\n",
    "    rated_movies = set(self.ratings_df[self.ratings_df['user_id'] == user_id]['movie_id'])\n",
    "    #Calculate the predicted ratings \n",
    "    user_vector = self.user_features[user_idx].reshape(1,-1)\n",
    "    predicted_ratings = np.dot(user_vector, self.movie_features.T)\n",
    "    #sort the movies and get the top n unrated movies \n",
    "    movie_indices = predicted_ratings.argsort()[::-1]\n",
    "\n",
    "    #Filter out already rated movies\n",
    "    unrated_indices = [i for i in movie_indices if self.movie_ids_cf[i] not in rated_movies][:n]\n",
    "        \n",
    "    # Get recommendation movie IDs\n",
    "    recommended_movie_ids = [self.movie_ids_cf[i] for i in unrated_indices]\n",
    "    recommendation_scores = predicted_ratings[unrated_indices]\n",
    "        \n",
    "    # Get movie details\n",
    "    recommendations = self.movies_df[self.movies_df['movie_id'].isin(recommended_movie_ids)].copy()\n",
    "        \n",
    "    # Add predicted rating\n",
    "    movie_id_to_score = {movie_id: score for movie_id, score in zip(recommended_movie_ids, recommendation_scores)}\n",
    "    recommendations['predicted_rating'] = recommendations['movie_id'].map(movie_id_to_score)\n",
    "        \n",
    "    # Sort by predicted rating\n",
    "    recommendations = recommendations.sort_values('predicted_rating', ascending=False)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c38394a5-dc1b-4b04-83c8-91d6fa2fb65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_recommendations(self, user_id, content_weight=0.3, n=10):\n",
    "    \"\"\"\n",
    "    Get hybrid recommendations combining content-based and collaborative filtering\n",
    "        \n",
    "    Parameters:\n",
    "    user_id: ID of the user to get recommendations for\n",
    "    content_weight (float): Weight for content-based recommendations (0-1)\n",
    "    n (int): Number of recommendations to return\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame: Top n recommended movies using the hybrid approach\n",
    "    \"\"\"\n",
    "    # Get user's highest rated movies\n",
    "    if self.ratings_df is None:\n",
    "        raise ValueError(\"Ratings data not loaded. Cannot build hybrid recommendations.\")\n",
    "            \n",
    "    user_ratings = self.ratings_df[self.ratings_df['user_id'] == user_id]\n",
    "    if len(user_ratings) == 0:\n",
    "        raise ValueError(f\"No ratings found for user ID {user_id}\")\n",
    "            \n",
    "     # Get top rated movie for content-based recommendations\n",
    "    top_rated_movie = user_ratings.sort_values('rating', ascending=False).iloc[0]['movie_id']\n",
    "        \n",
    "    # Get content-based recommendations from user's top movie\n",
    "    content_recs = self.get_content_based_recommendations(top_rated_movie, n=50)\n",
    "        \n",
    "    # Get collaborative filtering recommendations\n",
    "    collab_recs = self.get_collaborative_recommendations(user_id, n=50)\n",
    "        \n",
    "    # Combine the recommendations\n",
    "    # Normalize the scores\n",
    "    content_recs['norm_score'] = (content_recs['similarity_score'] - content_recs['similarity_score'].min()) / \\\n",
    "                                     (content_recs['similarity_score'].max() - content_recs['similarity_score'].min())\n",
    "        \n",
    "    collab_recs['norm_score'] = (collab_recs['predicted_rating'] - collab_recs['predicted_rating'].min()) / \\\n",
    "                                   (collab_recs['predicted_rating'].max() - collab_recs['predicted_rating'].min())\n",
    "        \n",
    "    # Create a set of all recommended movies\n",
    "    all_movies = set(content_recs['movie_id']).union(set(collab_recs['movie_id']))\n",
    "        \n",
    "    # Calculate hybrid scores\n",
    "    hybrid_scores = {}\n",
    "    for movie_id in all_movies:\n",
    "        content_score = content_recs[content_recs['movie_id'] == movie_id]['norm_score'].values\n",
    "        content_score = content_score[0] if len(content_score) > 0 else 0\n",
    "            \n",
    "        collab_score = collab_recs[collab_recs['movie_id'] == movie_id]['norm_score'].values\n",
    "        collab_score = collab_score[0] if len(collab_score) > 0 else 0\n",
    "            \n",
    "        # Weighted average\n",
    "        hybrid_scores[movie_id] = content_weight * content_score + (1 - content_weight) * collab_score\n",
    "        \n",
    "    # Sort by hybrid score\n",
    "    sorted_movies = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_movie_ids = [movie_id for movie_id, _ in sorted_movies[:n]]\n",
    "        \n",
    "    # Get movie details\n",
    "    recommendations = self.movies_df[self.movies_df['movie_id'].isin(top_movie_ids)].copy()\n",
    "        \n",
    "    # Add hybrid score\n",
    "    recommendations['hybrid_score'] = recommendations['movie_id'].map(hybrid_scores)\n",
    "        \n",
    "    # Sort by hybrid score\n",
    "    recommendations = recommendations.sort_values('hybrid_score', ascending=False)\n",
    "        \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1b42efe-2878-4810-925b-2f6e1e493b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trending_recommendations(self, timeframe='month', n=10):\n",
    "    \"\"\"\n",
    "     Get trending movies based on recent popularity\n",
    "        \n",
    "    Parameters:\n",
    "    timeframe (str): Time frame for trending ('week', 'month', 'year')\n",
    "    n (int): Number of recommendations to return\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame: Top n trending movies\n",
    "    \"\"\"\n",
    "    if self.ratings_df is None or 'timestamp' not in self.ratings_df.columns:\n",
    "        raise ValueError(\"Ratings data with timestamps not available\")\n",
    "        \n",
    "    # Convert timestamp to datetime\n",
    "    self.ratings_df['date'] = pd.to_datetime(self.ratings_df['timestamp'], unit='s')\n",
    "        \n",
    "    # Filter recent ratings based on timeframe\n",
    "    now = pd.Timestamp.now()\n",
    "    if timeframe == 'week':\n",
    "        recent_ratings = self.ratings_df[self.ratings_df['date'] > (now - pd.Timedelta(days=7))]\n",
    "    elif timeframe == 'month':\n",
    "        recent_ratings = self.ratings_df[self.ratings_df['date'] > (now - pd.Timedelta(days=30))]\n",
    "    elif timeframe == 'year':\n",
    "        recent_ratings = self.ratings_df[self.ratings_df['date'] > (now - pd.Timedelta(days=365))]\n",
    "    else:\n",
    "        recent_ratings = self.ratings_df\n",
    "        \n",
    "    # Calculate popularity score (avg rating * number of ratings)\n",
    "    popularity = recent_ratings.groupby('movie_id').agg(\n",
    "        avg_rating=('rating', 'mean'),\n",
    "        num_ratings=('rating', 'count')\n",
    "    ).reset_index()\n",
    "        \n",
    "    # Calculate trending score\n",
    "    popularity['trending_score'] = popularity['avg_rating'] * np.log1p(popularity['num_ratings'])\n",
    "        \n",
    "    # Get top trending movies\n",
    "    top_trending = popularity.sort_values('trending_score', ascending=False).head(n)\n",
    "        \n",
    "    # Get movie details\n",
    "    trending_recs = self.movies_df[self.movies_df['movie_id'].isin(top_trending['movie_id'])].copy()\n",
    "        \n",
    "    # Add trending score\n",
    "    trending_recs = trending_recs.merge(\n",
    "        top_trending[['movie_id', 'trending_score', 'avg_rating', 'num_ratings']], \n",
    "        on='movie_id'\n",
    "    )\n",
    "        \n",
    "    return trending_recs.sort_values('trending_score', ascending=False)\n",
    "    \n",
    "def get_personalized_for_you(self, user_id, n=10):\n",
    "    \"\"\"\n",
    "    Get personalized 'For You' recommendations based on user watch history\n",
    "        \n",
    "    Parameters:\n",
    "    user_id: ID of the user to get recommendations for\n",
    "    n (int): Number of recommendations to return\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame: Top n personalized recommendations\n",
    "    \"\"\"\n",
    "    # This is a more personalized version focusing on user's specific tastes\n",
    "    return self.get_hybrid_recommendations(user_id, content_weight=0.6, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e831f8f0-c6ea-439e-a38f-2a7ca27934f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_because_you_watched(self, movie_id, n=10):\n",
    "    \"\"\"\n",
    "    Get recommendations based on a specific movie (Netflix's \"Because you watched X\")\n",
    "        \n",
    "    Parameters:\n",
    "    movie_id: ID of the movie to base recommendations on\n",
    "    n (int): Number of recommendations to return\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame: Top n recommendations\n",
    "    \"\"\"\n",
    "    # This is simply content-based filtering using a specific movie\n",
    "    return self.get_content_based_recommendations(movie_id, n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d69e8a41-a0db-4f91-819c-cc87c190f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user_preferences(self, user_id):\n",
    "    \"\"\"\n",
    "    Analyze user preferences to understand their tastes\n",
    "        \n",
    "    Parameters:\n",
    "    user_id: ID of the user to analyze\n",
    "        \n",
    "    Returns:\n",
    "    dict: User preference analysis\n",
    "    \"\"\"\n",
    "    if self.ratings_df is None:\n",
    "        raise ValueError(\"Ratings data not loaded\")\n",
    "            \n",
    "    user_ratings = self.ratings_df[self.ratings_df['user_id'] == user_id]\n",
    "    if len(user_ratings) == 0:\n",
    "        raise ValueError(f\"No ratings found for user ID {user_id}\")\n",
    "            \n",
    "    # Get movies the user has rated\n",
    "    rated_movies = self.movies_df[self.movies_df['movie_id'].isin(user_ratings['movie_id'])]\n",
    "        \n",
    "    # Merge ratings with movie details\n",
    "    user_data = rated_movies.merge(user_ratings[['movie_id', 'rating']], on='movie_id')\n",
    "        \n",
    "    # Calculate genre preferences if genre data is available\n",
    "    genre_prefs = {}\n",
    "    if 'genres' in rated_movies.columns:\n",
    "        # Assuming genres are stored as comma-separated strings\n",
    "        all_genres = []\n",
    "        for genres in rated_movies['genres']:\n",
    "            all_genres.extend([g.strip() for g in str(genres).split(',')])\n",
    "            \n",
    "        unique_genres = list(set(all_genres))\n",
    "            \n",
    "        for genre in unique_genres:\n",
    "            # Calculate average rating for each genre\n",
    "            genre_movies = user_data[user_data['genres'].str.contains(genre, na=False)]\n",
    "            if len(genre_movies) > 0:\n",
    "                avg_rating = genre_movies['rating'].mean()\n",
    "                genre_prefs[genre] = {\n",
    "                    'avg_rating': avg_rating,\n",
    "                    'movies_count': len(genre_movies)\n",
    "                }\n",
    "        \n",
    "        # Calculate most watched timeframes if timestamp data is available\n",
    "    time_prefs = {}\n",
    "    if 'timestamp' in user_ratings.columns:\n",
    "        user_ratings['date'] = pd.to_datetime(user_ratings['timestamp'], unit='s')\n",
    "        user_ratings['hour'] = user_ratings['date'].dt.hour\n",
    "        user_ratings['day_of_week'] = user_ratings['date'].dt.day_name()\n",
    "            \n",
    "        # Most active hours\n",
    "        hour_counts = user_ratings['hour'].value_counts()\n",
    "        peak_hours = hour_counts.nlargest(3).index.tolist()\n",
    "            \n",
    "        # Most active days\n",
    "        day_counts = user_ratings['day_of_week'].value_counts()\n",
    "        peak_days = day_counts.nlargest(3).index.tolist()\n",
    "            \n",
    "        time_prefs = {\n",
    "            'peak_hours': peak_hours,\n",
    "            'peak_days': peak_days\n",
    "        }\n",
    "        \n",
    "    # Overall stats\n",
    "    overall_stats = {\n",
    "        'total_ratings': len(user_ratings),\n",
    "        'avg_rating': user_ratings['rating'].mean(),\n",
    "        'top_rated': rated_movies.loc[user_ratings['rating'].idxmax()]['title'] \n",
    "                    if len(user_ratings) > 0 else None,\n",
    "        'recently_watched': rated_movies.loc[user_ratings['timestamp'].idxmax()]['title'] \n",
    "                             if 'timestamp' in user_ratings.columns and len(user_ratings) > 0 else None\n",
    "        }\n",
    "        \n",
    "    return {\n",
    "        'overall_stats': overall_stats,\n",
    "        'genre_preferences': genre_prefs,\n",
    "        'time_preferences': time_prefs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9c618956-3a65-4089-9be8-b7c6fcd9e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_user_preferences(self, user_id):\n",
    "    \"\"\"\n",
    "    Visualize user preferences\n",
    "        \n",
    "    Parameters:\n",
    "    user_id: ID of the user to visualize preferences for\n",
    "    \"\"\"\n",
    "    if self.ratings_df is None:\n",
    "        raise ValueError(\"Ratings data not loaded\")\n",
    "            \n",
    "    user_ratings = self.ratings_df[self.ratings_df['user_id'] == user_id]\n",
    "    if len(user_ratings) == 0:\n",
    "        raise ValueError(f\"No ratings found for user ID {user_id}\")\n",
    "            \n",
    "     # Get movies the user has rated\n",
    "    rated_movies = self.movies_df[self.movies_df['movie_id'].isin(user_ratings['movie_id'])]\n",
    "        \n",
    "    # Merge ratings with movie details\n",
    "    user_data = rated_movies.merge(user_ratings[['movie_id', 'rating']], on='movie_id')\n",
    "        \n",
    "    plt.figure(figsize=(15, 10))\n",
    "        \n",
    "    # Rating distribution\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.histplot(user_data['rating'], bins=10, kde=True)\n",
    "    plt.title(f'Rating Distribution for User {user_id}')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "        \n",
    "    # Genre preferences if available\n",
    "    if 'genres' in rated_movies.columns:\n",
    "        plt.subplot(2, 2, 2)\n",
    "            \n",
    "        # Process genres\n",
    "        genre_data = []\n",
    "        for idx, row in user_data.iterrows():\n",
    "            genres = str(row['genres']).split(',')\n",
    "            for genre in genres:\n",
    "                genre = genre.strip()\n",
    "                if genre:\n",
    "                    genre_data.append({\n",
    "                        'genre': genre,\n",
    "                        'rating': row['rating']\n",
    "                    })\n",
    "            \n",
    "        genre_df = pd.DataFrame(genre_data)\n",
    "        genre_avg = genre_df.groupby('genre')['rating'].mean().sort_values(ascending=False)\n",
    "            \n",
    "        # Plot top genres\n",
    "        top_genres = genre_avg.head(10)\n",
    "        sns.barplot(x=top_genres.values, y=top_genres.index)\n",
    "        plt.title(f'Top Genres by Average Rating for User {user_id}')\n",
    "        plt.xlabel('Average Rating')\n",
    "    if 'timestamp' in user_ratings.columns:\n",
    "        plt.subplot(2, 2, 3)\n",
    "        user_ratings['date'] = pd.to_datetime(user_ratings['timestamp'], unit='s')\n",
    "        user_ratings = user_ratings.sort_values('date')\n",
    "        sns.lineplot(x=user_ratings['date'], y=user_ratings['rating'])\n",
    "        plt.title(f'Rating Trend Over Time for User {user_id}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Rating')\n",
    "            \n",
    "        # Watch activity heatmap by hour and day\n",
    "        plt.subplot(2, 2, 4)\n",
    "        user_ratings['hour'] = user_ratings['date'].dt.hour\n",
    "        user_ratings['day'] = user_ratings['date'].dt.dayofweek\n",
    "            \n",
    "        watch_pivot = pd.pivot_table(\n",
    "            user_ratings,\n",
    "            values='movie_id',\n",
    "            index='day',\n",
    "            columns='hour',\n",
    "            aggfunc='count',\n",
    "            fill_value=0\n",
    "        )\n",
    "        sns.heatmap(watch_pivot, cmap='YlGnBu')\n",
    "        plt.title(f'Watch Activity Heatmap for User {user_id}')\n",
    "        plt.xlabel('Hour of Day')\n",
    "        plt.ylabel('Day of Week (0=Monday)')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cd3c8b8-6b51-4d4d-9cc1-7de4503d3493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data with 100 movies, 500 users, and 5000 ratings\n",
      "Generated 100 movies, 500 users, and 4753 ratings\n",
      "Sample data files saved to .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "class IFFADataScraper:\n",
    "    def __init__(self, base_url=\"https://www.iffa.com.au\"):\n",
    "        self.base_url = base_url\n",
    "        self.movies_data = []\n",
    "\n",
    "    def scrape_movies(self):\n",
    "        \"\"\"Scrape movie data from IFFA Australia website\"\"\"\n",
    "        try:\n",
    "            # Send request to the main page\n",
    "            response = requests.get(self.base_url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Find movie links - this is a placeholder, you'll need to inspect the actual website\n",
    "            movie_links = soup.select('a.movie-link')  # Adjust selector based on actual HTML structure\n",
    "            \n",
    "            for link in movie_links:\n",
    "                movie_url = link.get('href')\n",
    "                if not movie_url.startswith('http'):\n",
    "                    movie_url = self.base_url + movie_url\n",
    "                \n",
    "                # Scrape individual movie page\n",
    "                self._scrape_movie_page(movie_url)\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            movies_df = pd.DataFrame(self.movies_data)\n",
    "            return movies_df\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error scraping IFFA website: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def _scrape_movie_page(self, url):\n",
    "        \"\"\"Scrape data from an individual movie page\"\"\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract movie details - adjust selectors based on actual HTML structure\n",
    "            movie_data = {\n",
    "                'movie_id': self._generate_movie_id(url),\n",
    "                'title': self._extract_text(soup, 'h1.movie-title'),\n",
    "                'genres': self._extract_text(soup, 'div.genres'),\n",
    "                'director': self._extract_text(soup, 'div.director'),\n",
    "                'cast': self._extract_text(soup, 'div.cast'),\n",
    "                'description': self._extract_text(soup, 'div.description'),\n",
    "                'release_year': self._extract_text(soup, 'div.year'),\n",
    "                'duration': self._extract_text(soup, 'div.duration'),\n",
    "                'url': url,\n",
    "                'image_url': self._extract_attribute(soup, 'img.movie-poster', 'src')\n",
    "            }\n",
    "            \n",
    "            self.movies_data.append(movie_data)\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error scraping movie page {url}: {e}\")\n",
    "\n",
    "    def _extract_text(self, soup, selector):\n",
    "        \"\"\"Extract text from a BeautifulSoup element\"\"\"\n",
    "        element = soup.select_one(selector)\n",
    "        return element.text.strip() if element else ''\n",
    "\n",
    "    def _extract_attribute(self, soup, selector, attribute):\n",
    "        \"\"\"Extract an attribute from a BeautifulSoup element\"\"\"\n",
    "        element = soup.select_one(selector)\n",
    "        return element.get(attribute, '') if element else ''\n",
    "\n",
    "    def _generate_movie_id(self, url):\n",
    "        \"\"\"Generate a unique movie ID from URL\"\"\"\n",
    "        # Extract ID from URL if possible\n",
    "        match = re.search(r'movie[/=](\\d+)', url)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        \n",
    "        # Otherwise hash the URL\n",
    "        return abs(hash(url)) % 10000000\n",
    "\n",
    "    def generate_synthetic_data(self, num_movies=100, num_users=500, num_ratings=5000):\n",
    "        \"\"\"\n",
    "        Generate synthetic data for testing when web scraping isn't possible\n",
    "        \n",
    "        Parameters:\n",
    "        num_movies (int): Number of movies to generate\n",
    "        num_users (int): Number of users to generate\n",
    "        num_ratings (int): Number of ratings to generate\n",
    "        \n",
    "        Returns:\n",
    "        tuple: (movies_df, users_df, ratings_df)\n",
    "        \"\"\"\n",
    "        print(f\"Generating synthetic data with {num_movies} movies, {num_users} users, and {num_ratings} ratings\")\n",
    "        \n",
    "        # Define movie genres for IFFA (film festival context)\n",
    "        genres = [\n",
    "            \"Drama\", \"Comedy\", \"Documentary\", \"Short Film\", \"Animation\", \n",
    "            \"Thriller\", \"Horror\", \"Experimental\", \"Romance\", \"Action\",\n",
    "            \"Science Fiction\", \"Fantasy\", \"Adventure\", \"Mystery\", \"Historical\"\n",
    "        ]\n",
    "        \n",
    "        # Define directors and cast members (placeholder names)\n",
    "        directors = [\n",
    "            \"Jane Smith\", \"John Doe\", \"Emma Johnson\", \"Michael Brown\", \"Sarah Davis\",\n",
    "            \"David Wilson\", \"Lisa Anderson\", \"Robert Taylor\", \"Jennifer Martinez\", \"James Thompson\"\n",
    "        ]\n",
    "        \n",
    "        cast_members = [\n",
    "            \"Emma Stone\", \"Chris Hemsworth\", \"Cate Blanchett\", \"Hugh Jackman\", \"Nicole Kidman\",\n",
    "            \"Sam Worthington\", \"Margot Robbie\", \"Russell Crowe\", \"Naomi Watts\", \"Eric Bana\",\n",
    "            \"Toni Collette\", \"Joel Edgerton\", \"Rose Byrne\", \"Guy Pearce\", \"Isla Fisher\",\n",
    "            \"Jason Clarke\", \"Rebel Wilson\", \"Ben Mendelsohn\", \"Mia Wasikowska\", \"Simon Baker\"\n",
    "        ]\n",
    "        \n",
    "        # Generate movie data\n",
    "        movies_data = []\n",
    "        for i in range(1, num_movies + 1):\n",
    "            # Randomly select 1-3 genres\n",
    "            num_genres = np.random.randint(1, 4)\n",
    "            movie_genres = \", \".join(np.random.choice(genres, num_genres, replace=False))\n",
    "            \n",
    "            # Randomly select director\n",
    "            director = np.random.choice(directors)\n",
    "            \n",
    "            # Randomly select 2-5 cast members\n",
    "            num_cast = np.random.randint(2, 6)\n",
    "            movie_cast = \", \".join(np.random.choice(cast_members, num_cast, replace=False))\n",
    "            \n",
    "            # Generate random year between 2010 and 2024\n",
    "            year = np.random.randint(2010, 2025)\n",
    "            \n",
    "            # Generate a random duration between 60 and 180 minutes\n",
    "            duration = np.random.randint(60, 181)\n",
    "            \n",
    "            # Create a movie description\n",
    "            descriptions = [\n",
    "                f\"A compelling {movie_genres.split(',')[0].strip().lower()} film that explores the complexities of human relationships.\",\n",
    "                f\"An award-winning {movie_genres.split(',')[0].strip().lower()} masterpiece that captivates audiences with its stunning visuals.\",\n",
    "                f\"A thought-provoking journey through {movie_genres.split(',')[0].strip().lower()} themes that challenges conventional thinking.\",\n",
    "                f\"A groundbreaking {movie_genres.split(',')[0].strip().lower()} narrative that showcases Australian filmmaking at its finest.\",\n",
    "                f\"An emotionally charged {movie_genres.split(',')[0].strip().lower()} experience that resonates with audiences long after viewing.\"\n",
    "            ]\n",
    "            description = np.random.choice(descriptions)\n",
    "            \n",
    "            # Generate a movie title\n",
    "            title_adjectives = [\"Lost\", \"Hidden\", \"Eternal\", \"Broken\", \"Silent\", \"Wild\", \"Golden\", \"Distant\", \"Secret\", \"Forgotten\"]\n",
    "            title_nouns = [\"Dreams\", \"Light\", \"Journey\", \"Sunset\", \"Waters\", \"Echo\", \"Whisper\", \"Horizon\", \"Shadow\", \"Promise\"]\n",
    "            \n",
    "            title = f\"The {np.random.choice(title_adjectives)} {np.random.choice(title_nouns)}\"\n",
    "            \n",
    "            movies_data.append({\n",
    "                'movie_id': i,\n",
    "                'title': title,\n",
    "                'genres': movie_genres,\n",
    "                'director': director,\n",
    "                'cast': movie_cast,\n",
    "                'description': description,\n",
    "                'release_year': year,\n",
    "                'duration': duration,\n",
    "                'url': f\"https://iffa.com.au/movies/{i}\",\n",
    "                'image_url': f\"https://iffa.com.au/images/movies/{i}.jpg\",\n",
    "                'keywords': movie_genres.replace(\", \", \",\"),  # For content-based filtering\n",
    "                'tags': movie_genres.replace(\", \", \",\")  # For content-based filtering\n",
    "            })\n",
    "        \n",
    "        # Create movies DataFrame\n",
    "        movies_df = pd.DataFrame(movies_data)\n",
    "        \n",
    "        # Generate user data\n",
    "        users_data = []\n",
    "        for i in range(1, num_users + 1):\n",
    "            # Generate random age between 18 and 80\n",
    "            age = np.random.randint(18, 81)\n",
    "            \n",
    "            # Generate random gender\n",
    "            gender = np.random.choice(['M', 'F', 'Other'])\n",
    "            \n",
    "            # Generate random location\n",
    "            locations = [\"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\", \n",
    "                         \"Canberra\", \"Hobart\", \"Darwin\", \"Gold Coast\", \"Newcastle\"]\n",
    "            location = np.random.choice(locations)\n",
    "            \n",
    "            # Generate random favorite genres (1-3)\n",
    "            num_fav_genres = np.random.randint(1, 4)\n",
    "            favorite_genres = \", \".join(np.random.choice(genres, num_fav_genres, replace=False))\n",
    "            \n",
    "            # Generate registration date\n",
    "            # Random date between Jan 1, 2020 and today\n",
    "            start_date = datetime.datetime(2020, 1, 1).timestamp()\n",
    "            end_date = datetime.datetime.now().timestamp()\n",
    "            reg_timestamp = np.random.randint(start_date, end_date)\n",
    "            reg_date = datetime.datetime.fromtimestamp(reg_timestamp).strftime('%Y-%m-%d')\n",
    "            \n",
    "            # Generate subscription type\n",
    "            sub_types = [\"Free\", \"Basic\", \"Premium\", \"Festival Pass\"]\n",
    "            subscription = np.random.choice(sub_types)\n",
    "            \n",
    "            users_data.append({\n",
    "                'user_id': i,\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'location': location,\n",
    "                'favorite_genres': favorite_genres,\n",
    "                'registration_date': reg_date,\n",
    "                'subscription_type': subscription\n",
    "            })\n",
    "        \n",
    "        # Create users DataFrame\n",
    "        users_df = pd.DataFrame(users_data)\n",
    "        \n",
    "        # Generate ratings data\n",
    "        ratings_data = []\n",
    "        \n",
    "        # Start timestamp - January 1, 2020\n",
    "        start_timestamp = datetime.datetime(2020, 1, 1).timestamp()\n",
    "        \n",
    "        # End timestamp - current time\n",
    "        end_timestamp = datetime.datetime.now().timestamp()\n",
    "        \n",
    "        # Generate random user-movie ratings\n",
    "        for _ in range(num_ratings):\n",
    "            user_id = np.random.randint(1, num_users + 1)\n",
    "            movie_id = np.random.randint(1, num_movies + 1)\n",
    "            \n",
    "            # Generate rating between 1 and 5, with 0.5 increments\n",
    "            rating = np.random.choice([1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5])\n",
    "            \n",
    "            # Generate random timestamp for the rating\n",
    "            timestamp = np.random.randint(start_timestamp, end_timestamp)\n",
    "            \n",
    "            ratings_data.append({\n",
    "                'user_id': user_id,\n",
    "                'movie_id': movie_id,\n",
    "                'rating': rating,\n",
    "                'timestamp': timestamp\n",
    "            })\n",
    "        \n",
    "        # Create ratings DataFrame\n",
    "        ratings_df = pd.DataFrame(ratings_data)\n",
    "        \n",
    "        # Remove duplicate user-movie pairs and keep only the most recent rating\n",
    "        ratings_df = ratings_df.sort_values('timestamp', ascending=False).drop_duplicates(['user_id', 'movie_id']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Generated {len(movies_df)} movies, {len(users_df)} users, and {len(ratings_df)} ratings\")\n",
    "        \n",
    "        return movies_df, users_df, ratings_df\n",
    "    \n",
    "    def generate_sample_data_files(self, output_dir='.'):\n",
    "        \"\"\"\n",
    "        Generate and save sample data files for testing\n",
    "        \n",
    "        Parameters:\n",
    "        output_dir (str): Directory to save the generated files\n",
    "        \"\"\"\n",
    "        movies_df, users_df, ratings_df = self.generate_synthetic_data()\n",
    "        \n",
    "        # Save to CSV files\n",
    "        movies_df.to_csv(f\"{output_dir}/iffa_movies.csv\", index=False)\n",
    "        users_df.to_csv(f\"{output_dir}/iffa_users.csv\", index=False)\n",
    "        ratings_df.to_csv(f\"{output_dir}/iffa_ratings.csv\", index=False)\n",
    "        \n",
    "        print(f\"Sample data files saved to {output_dir}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = IFFADataScraper()\n",
    "    scraper.generate_sample_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbcd67d5-8ed6-4137-a6bd-7818018ac3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100 movies\n",
      "Loaded 4753 ratings\n",
      "Loaded 500 users\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'IFFARecommendationSystem' object has no attribute 'build_content_based_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 61\u001b[0m\n\u001b[0;32m     57\u001b[0m     recommender\u001b[38;5;241m.\u001b[39mvisualize_user_preferences(user_id)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     demo_recommender()\n",
      "Cell \u001b[1;32mIn[86], line 13\u001b[0m, in \u001b[0;36mdemo_recommender\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m recommender\u001b[38;5;241m.\u001b[39mload_data(\n\u001b[0;32m      7\u001b[0m     movies_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miffa_movies.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     ratings_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miffa_ratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m     users_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miffa_users.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Build recommendation models\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m recommender\u001b[38;5;241m.\u001b[39mbuild_content_based_model()\n\u001b[0;32m     14\u001b[0m recommender\u001b[38;5;241m.\u001b[39mbuild_collaborative_filtering_model()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Get different types of recommendations\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 1. Content-based recommendations for a movie\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'IFFARecommendationSystem' object has no attribute 'build_content_based_model'"
     ]
    }
   ],
   "source": [
    "def demo_recommender():\n",
    "    # Create recommender system\n",
    "    recommender = IFFARecommendationSystem()\n",
    "    \n",
    "    # Load data (example paths - update with your actual data)\n",
    "    recommender.load_data(\n",
    "        movies_path='iffa_movies.csv',\n",
    "        ratings_path='iffa_ratings.csv',\n",
    "        users_path='iffa_users.csv'\n",
    "    )\n",
    "    \n",
    "    # Build recommendation models\n",
    "    recommender.build_content_based_model()\n",
    "    recommender.build_collaborative_filtering_model()\n",
    "    \n",
    "    # Get different types of recommendations\n",
    "    \n",
    "    # 1. Content-based recommendations for a movie\n",
    "    movie_id = 12345  # Replace with actual movie ID\n",
    "    content_recs = recommender.get_content_based_recommendations(movie_id)\n",
    "    print(\"\\nContent-based recommendations:\")\n",
    "    print(content_recs[['title', 'similarity_score']])\n",
    "    \n",
    "    # 2. Collaborative filtering recommendations for a user\n",
    "    user_id = 42  # Replace with actual user ID\n",
    "    collab_recs = recommender.get_collaborative_recommendations(user_id)\n",
    "    print(\"\\nCollaborative filtering recommendations:\")\n",
    "    print(collab_recs[['title', 'predicted_rating']])\n",
    "    \n",
    "    # 3. Hybrid recommendations\n",
    "    hybrid_recs = recommender.get_hybrid_recommendations(user_id)\n",
    "    print(\"\\nHybrid recommendations:\")\n",
    "    print(hybrid_recs[['title', 'hybrid_score']])\n",
    "    \n",
    "    # 4. Trending recommendations\n",
    "    trending_recs = recommender.get_trending_recommendations(timeframe='week')\n",
    "    print(\"\\nTrending this week:\")\n",
    "    print(trending_recs[['title', 'trending_score', 'avg_rating', 'num_ratings']])\n",
    "    \n",
    "    # 5. \"For You\" personalized recommendations\n",
    "    for_you_recs = recommender.get_personalized_for_you(user_id)\n",
    "    print(\"\\nFor You recommendations:\")\n",
    "    print(for_you_recs[['title', 'hybrid_score']])\n",
    "    \n",
    "    # 6. \"Because you watched\" recommendations\n",
    "    watched_movie_id = 67890  # Replace with actual movie ID\n",
    "    because_you_watched = recommender.get_because_you_watched(watched_movie_id)\n",
    "    print(\"\\nBecause you watched recommendations:\")\n",
    "    print(because_you_watched[['title', 'similarity_score']])\n",
    "    \n",
    "    # 7. Analyze user preferences\n",
    "    user_prefs = recommender.analyze_user_preferences(user_id)\n",
    "    print(\"\\nUser preferences analysis:\")\n",
    "    print(user_prefs)\n",
    "    \n",
    "    # 8. Visualize user preferences\n",
    "    recommender.visualize_user_preferences(user_id)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25bf1a0-5fbd-4ec6-9ca3-bc2c73c79bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
